#!/usr/bin/env bash
# scan_compromised
# Usage:
#   scan_compromised                  # scan current project (behaviour as before)
#   scan_compromised --compromised-file /path/to/list.txt
#   scan_compromised --paths-file /path/to/projects.txt
#   scan_compromised --paths-file /p.txt --compromised-file /c.txt
#
# paths-file: one project directory per line (absolute or relative).
# compromised-file: one package name per line (scoped names allowed). Comments with #.

set -euo pipefail

# ---------- helpers ----------
err() { echo "ERROR: $*" >&2; }
info() { echo "$*"; }

# resolve script real path (follow symlinks)
resolve_script_dir() {
  local SOURCE="${BASH_SOURCE[0]}"
  while [ -L "$SOURCE" ]; do
    local DIR
    DIR="$(cd -P "$(dirname "$SOURCE")" >/dev/null 2>&1 && pwd)"
    SOURCE="$(readlink "$SOURCE")"
    [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE"
  done
  printf '%s' "$(cd -P "$(dirname "$SOURCE")" >/dev/null 2>&1 && pwd)"
}

SCRIPT_DIR="$(resolve_script_dir)"

# ---------- parse args ----------
COMPROMISED_FILE=""
PATHS_FILE=""
while [ "${1:-}" != "" ]; do
  case "$1" in
    --compromised-file)
      shift
      COMPROMISED_FILE="$1"
      ;;
    --paths-file)
      shift
      PATHS_FILE="$1"
      ;;
    --help|-h)
      cat <<EOF
Usage:
  scan_compromised [--compromised-file /path/to/compromised.txt] [--paths-file /path/to/projects.txt]

Behavior:
  - If --compromised-file omitted, the script will prefer:
      1) compromised.txt next to the real script
      2) compromised.txt in current dir or nearest ancestor (project-local)
  - If --paths-file provided, each non-empty, non-comment line is treated as a project directory to scan.
  - Without --paths-file the current working directory is scanned.

EOF
      exit 0
      ;;
    *)
      err "Unknown arg: $1"
      exit 2
      ;;
  esac
  shift
done

# ---------- find compromised list ----------
find_compromised_file() {
  if [ -n "$COMPROMISED_FILE" ]; then
    [ -f "$COMPROMISED_FILE" ] || { err "Specified compromised file not found: $COMPROMISED_FILE"; exit 2; }
    printf '%s' "$COMPROMISED_FILE"
    return
  fi

  # 1) next to script
  if [ -f "$SCRIPT_DIR/compromised.txt" ]; then
    printf '%s' "$SCRIPT_DIR/compromised.txt"
    return
  fi

  # 2) find in current dir -> parents
  local CUR="$PWD"
  while true; do
    if [ -f "$CUR/compromised.txt" ]; then
      printf '%s' "$CUR/compromised.txt"
      return
    fi
    [ "$CUR" = "/" ] && break
    CUR="$(dirname "$CUR")"
  done

  err "Missing compromised.txt. Provide one next to the script, in the current project, or pass --compromised-file"
  exit 2
}

COMP_FILE="$(find_compromised_file)"
info "Using compromised list: $COMP_FILE"

# ---------- read compromised list into array ----------
mapfile -t COMPROMISED_PKGS < <(grep -E -v '^[[:space:]]*(#|$)' "$COMP_FILE" || true)
if [ "${#COMPROMISED_PKGS[@]}" -eq 0 ]; then
  err "Compromised list is empty after filtering comments/blank lines."
  exit 2
fi

# ---------- utility to expand paths (tilde etc) ----------
expand_path() {
  local p="$1"
  # use parameter expansion via eval to expand ~ and relative paths safely
  # but avoid word-splitting
  printf '%s' "$(cd "$(eval "printf '%s' \"$p\"")" >/dev/null 2>&1 && pwd)" 2>/dev/null || return 1
}

# ---------- check for HTTP URLs in dependencies ----------
# Returns 0 if URLs found, 1 if not found
check_http_urls_in_dependencies() {
  local http_urls_found=0

  # Check package.json for HTTP URLs in dependencies
  if [ -f "package.json" ]; then
    # Check all dependency sections: dependencies, devDependencies, peerDependencies, optionalDependencies
    # Look for patterns like: "package-name": "http://..." or "package-name": "https://..."
    # Using jq if available, otherwise fall back to grep
    if command -v jq >/dev/null 2>&1; then
      # Use jq to extract all dependency values and check for URLs
      local deps_json
      deps_json=$(jq -r '.dependencies // {}, .devDependencies // {}, .peerDependencies // {}, .optionalDependencies // {} | to_entries[] | "\(.key)|\(.value)"' package.json 2>/dev/null || true)
      
      while IFS='|' read -r pkg_name pkg_version; do
        if [[ "$pkg_version" =~ ^(http|https):// ]]; then
          if [ "$http_urls_found" -eq 0 ]; then
            info "  ⚠️  HTTP/HTTPS URLs found in dependencies:"
            http_urls_found=1
          fi
          info "      - $pkg_name: $pkg_version (in package.json)"
        fi
      done <<< "$deps_json"
    else
      # Fallback: use grep to find HTTP/HTTPS URLs in package.json
      # Look for patterns like: "key": "http://..." or "key": "https://..."
      local url_matches
      url_matches=$(grep -E '"(http|https)://[^"]*"' package.json 2>/dev/null || true)
      if [ -n "$url_matches" ]; then
        if [ "$http_urls_found" -eq 0 ]; then
          info "  ⚠️  HTTP/HTTPS URLs found in dependencies:"
          http_urls_found=1
        fi
        while IFS= read -r line; do
          # Extract package name and URL from the line
          # Pattern: "package-name": "http://..."
          if [[ "$line" =~ \"([^\"]+)\":[[:space:]]*\"(http[s]?://[^\"]+)\" ]]; then
            info "      - ${BASH_REMATCH[1]}: ${BASH_REMATCH[2]} (in package.json)"
          else
            info "      - $line (in package.json)"
          fi
        done <<< "$url_matches"
      fi
    fi
  fi

  # Check lockfiles for HTTP URLs in transitive dependencies
  if [ -f "package-lock.json" ]; then
    # Check package-lock.json for HTTP URLs
    # In package-lock.json, URLs can appear in "resolved" fields
    if command -v jq >/dev/null 2>&1; then
      # Use jq to extract packages with HTTP URLs
      # Handle both v1 (dependencies tree) and v2+ (packages object) formats
      local pkg_urls
      pkg_urls=$(jq -r '
        # Check packages object (v2+ format) - contains ALL packages including nested
        (if .packages then 
          .packages | to_entries[] | 
          select(.value.resolved? // .value.version? | test("^https?://")) | 
          "\(.key)|\(.value.resolved // .value.version)"
        else empty end),
        # Check dependencies tree (v1 format) - recursively find ALL dependency objects
        # Use .. to recursively descend and find all objects with resolved/version fields
        (.. | objects | select(has("resolved") or has("version")) | 
         select((.resolved? // .version?) | test("^https?://")) |
         "\(.name // "unknown")|\(.resolved // .version)")
      ' package-lock.json 2>/dev/null || true)
      
      if [ -n "$pkg_urls" ]; then
        if [ "$http_urls_found" -eq 0 ]; then
          info "  ⚠️  HTTP/HTTPS URLs found in dependencies:"
          http_urls_found=1
        fi
        while IFS='|' read -r pkg_path url; do
          # Extract package name from path (e.g., "node_modules/@scope/pkg" -> "@scope/pkg")
          local pkg_name="${pkg_path##*/}"
          if [ "$pkg_path" != "$pkg_name" ] && [[ "$pkg_path" =~ node_modules/(.+) ]]; then
            pkg_name="${BASH_REMATCH[1]}"
          fi
          info "      - $pkg_name: $url (in package-lock.json)"
        done <<< "$pkg_urls"
      fi
    else
      # Fallback: use grep to find HTTP URLs
      local lockfile_urls
      lockfile_urls=$(grep -E '"(resolved|version)":\s*"(http|https)://[^"]*"' package-lock.json 2>/dev/null || true)
      if [ -n "$lockfile_urls" ]; then
        if [ "$http_urls_found" -eq 0 ]; then
          info "  ⚠️  HTTP/HTTPS URLs found in dependencies:"
          http_urls_found=1
        fi
        while IFS= read -r line; do
          # Try to extract URL
          if [[ "$line" =~ \"(resolved|version)\":[[:space:]]*\"(http[s]?://[^\"]+)\" ]]; then
            local url="${BASH_REMATCH[2]}"
            info "      - HTTP URL in package-lock.json: $url"
          fi
        done <<< "$lockfile_urls"
      fi
    fi
  elif [ -f "yarn.lock" ]; then
    # Check yarn.lock for HTTP URLs
    # In yarn.lock, URLs can appear as: "resolved" "http://..."
    # Format: package-name@version: ... resolved "http://..."
    local yarn_urls
    yarn_urls=$(grep -B 5 -E 'resolved\s+"(http|https)://[^"]*"' yarn.lock 2>/dev/null | grep -E '^"[^"]+@[^"]+":|resolved\s+"(http|https)://' || true)
    if [ -n "$yarn_urls" ]; then
      if [ "$http_urls_found" -eq 0 ]; then
        info "  ⚠️  HTTP/HTTPS URLs found in dependencies:"
        http_urls_found=1
      fi
      local current_pkg=""
      while IFS= read -r line; do
        # Extract package name from line like: "package-name@version:"
        if [[ "$line" =~ ^\"([^\"]+@[^\"]+)\": ]]; then
          current_pkg="${BASH_REMATCH[1]}"
        # Extract URL from line like: resolved "http://..."
        elif [[ "$line" =~ resolved[[:space:]]+\"(http[s]?://[^\"]+)\" ]]; then
          local url="${BASH_REMATCH[1]}"
          if [ -n "$current_pkg" ]; then
            info "      - $current_pkg: $url (in yarn.lock)"
          else
            info "      - HTTP URL in yarn.lock: $url"
          fi
        fi
      done <<< "$yarn_urls"
    fi
  elif [ -f "pnpm-lock.yaml" ]; then
    # Check pnpm-lock.yaml for HTTP URLs
    # In pnpm-lock.yaml, URLs can appear in "resolution" or "tarball" fields
    # Format: /package-name/version: ... resolution: http://...
    local pnpm_urls
    pnpm_urls=$(grep -B 3 -E '(resolution|tarball):\s*(http|https)://' pnpm-lock.yaml 2>/dev/null | grep -E '^[[:space:]]*/[^:]+:|(resolution|tarball):\s*(http|https)://' || true)
    if [ -n "$pnpm_urls" ]; then
      if [ "$http_urls_found" -eq 0 ]; then
        info "  ⚠️  HTTP/HTTPS URLs found in dependencies:"
        http_urls_found=1
      fi
      local current_pkg=""
      while IFS= read -r line; do
        # Extract package path from line like: "  /package-name/version:"
        if [[ "$line" =~ ^[[:space:]]*/([^:]+): ]]; then
          current_pkg="${BASH_REMATCH[1]}"
        # Extract URL from line like: resolution: http://...
        elif [[ "$line" =~ (resolution|tarball):[[:space:]]*(http[s]?://[^[:space:]]+) ]]; then
          local url="${BASH_REMATCH[2]}"
          if [ -n "$current_pkg" ]; then
            info "      - $current_pkg: $url (in pnpm-lock.yaml)"
          else
            info "      - HTTP URL in pnpm-lock.yaml: $url"
          fi
        fi
      done <<< "$pnpm_urls"
    fi
  fi

  # Check package.json files inside node_modules for HTTP URLs
  # This catches cases where a library's package.json has HTTP URLs that might not appear in lockfiles
  if [ -d "node_modules" ]; then
    local node_modules_pkgs
    # Find all package.json files in node_modules
    # We check all of them to catch HTTP URLs in any nested dependency's package.json
    node_modules_pkgs=$(find node_modules -name "package.json" -type f 2>/dev/null || true)
    
    if [ -n "$node_modules_pkgs" ]; then
      while IFS= read -r pkg_file; do
        # Extract package name from path (e.g., "node_modules/@scope/pkg/package.json" -> "@scope/pkg")
        local pkg_path="${pkg_file%/*}"
        local pkg_name="${pkg_path##*/}"
        if [[ "$pkg_path" =~ node_modules/(.+) ]]; then
          pkg_name="${BASH_REMATCH[1]}"
        fi
        
        # Check this package.json for HTTP URLs in dependencies
        if command -v jq >/dev/null 2>&1; then
          local deps_json
          deps_json=$(jq -r '.dependencies // {}, .devDependencies // {}, .peerDependencies // {}, .optionalDependencies // {} | to_entries[] | "\(.key)|\(.value)"' "$pkg_file" 2>/dev/null || true)
          
          while IFS='|' read -r dep_name dep_version; do
            if [[ "$dep_version" =~ ^(http|https):// ]]; then
              if [ "$http_urls_found" -eq 0 ]; then
                info "  ⚠️  HTTP/HTTPS URLs found in dependencies:"
                http_urls_found=1
              fi
              info "      - $dep_name: $dep_version (in $pkg_name/package.json)"
            fi
          done <<< "$deps_json"
        else
          # Fallback: use grep
          local url_matches
          url_matches=$(grep -E '"(http|https)://[^"]*"' "$pkg_file" 2>/dev/null || true)
          if [ -n "$url_matches" ]; then
            if [ "$http_urls_found" -eq 0 ]; then
              info "  ⚠️  HTTP/HTTPS URLs found in dependencies:"
              http_urls_found=1
            fi
            while IFS= read -r line; do
              if [[ "$line" =~ \"([^\"]+)\":[[:space:]]*\"(http[s]?://[^\"]+)\" ]]; then
                info "      - ${BASH_REMATCH[1]}: ${BASH_REMATCH[2]} (in $pkg_name/package.json)"
              fi
            done <<< "$url_matches"
          fi
        fi
      done <<< "$node_modules_pkgs"
    fi
  fi

  if [ "$http_urls_found" -eq 0 ]; then
    info "  ✓ No HTTP/HTTPS URLs found in dependencies"
    return 1
  else
    return 0
  fi
}

# ---------- scanning logic for a single project directory ----------
# Globals used: COMPROMISED_PKGS array
scan_one_project() {
  local project_dir="$1"
  local found_in_project=0
  local orig_dir
  orig_dir="$PWD"
  if ! cd "$project_dir" >/dev/null 2>&1; then
    err "Cannot enter directory: $project_dir"
    return 1  # non-fatal, skip (return 1 = falsy = not found)
  fi

  info "---- Project: $project_dir ----"
  # detect lockfile/manifest priority
  local LOCKFILE=""
  if [ -f "yarn.lock" ]; then
    LOCKFILE="yarn.lock"
  elif [ -f "package-lock.json" ]; then
    LOCKFILE="package-lock.json"
  elif [ -f "pnpm-lock.yaml" ]; then
    LOCKFILE="pnpm-lock.yaml"
  elif [ -f "package.json" ]; then
    LOCKFILE="package.json"
  fi

  info "  Scanning files: ${LOCKFILE:-'(no lockfile/package.json found)'}"

  # check for HTTP URLs in dependencies
  if check_http_urls_in_dependencies; then
    found_in_project=1
  fi

  # iterate pkgs
  for raw in "${COMPROMISED_PKGS[@]}"; do
    pkg="$raw"
    # basic sanitize / trim (should be fine already)
    pkg="$(echo "$pkg" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')"
    [ -z "$pkg" ] && continue

    printf "  › %-30s" "$pkg"

    local reported=0

    # check lockfile/manifest
    if [ -n "$LOCKFILE" ]; then
      # Escape special regex characters in package name, but preserve / for scoped packages
      pkg_escaped=$(printf '%s\n' "$pkg" | sed 's/[.[\*^$+?{|()]/\\&/g')
      if grep -q -E "(^|\"|[[:space:]])${pkg_escaped}(@|:|[[:space:]]|$)" "$LOCKFILE" 2>/dev/null; then
        printf " FOUND in %s\n" "$LOCKFILE"
        reported=1
        found_in_project=1
      else
        printf " not-in-lockfile"
      fi
    else
      printf " (no-lockfile)"
    fi

    # quick node_modules check
    # Note: node_modules/$pkg works for both regular packages (node_modules/pkg) 
    # and scoped packages (node_modules/@scope/pkg)
    if [ -d "node_modules/$pkg" ]; then
      printf ", installed"
      reported=1
      found_in_project=1
    fi

    # run yarn why ONLY if package seems present (found in lockfile or node_modules) and yarn exists
    if [ "$reported" -eq 1 ] && command -v yarn >/dev/null 2>&1; then
      # use temp file
      TMPY="/tmp/scan_compromised_yarn_$$"
      if yarn why "$pkg" >"$TMPY" 2>/dev/null; then
        printf ", yarn-why OK\n"
        sed -n '1,3p' "$TMPY" | sed 's/^/      /'
      else
        printf ", yarn-why no-info\n"
      fi
      rm -f "$TMPY" >/dev/null 2>&1 || true
    else
      printf "\n"
    fi
  done

  # global checks (only when scanning the filesystem of the current user - best-effort)
  # show if any compromised pkg found in this project
  if [ "$found_in_project" -ne 0 ]; then
    info "  -> Compromised package(s) FOUND in project: $project_dir"
  else
    info "  -> No compromised packages found in project."
  fi

  cd "$orig_dir" >/dev/null 2>&1 || true
  # Return 0 (success/truthy) if found, 1 (failure/falsy) if not found
  # This way the if statement correctly detects when packages were found
  return $((found_in_project == 0 ? 1 : 0))
}

# ---------- run scanning across a list of paths or single project ----------
ANY_FOUND=0

if [ -n "$PATHS_FILE" ]; then
  if [ ! -f "$PATHS_FILE" ]; then
    err "Paths file not found: $PATHS_FILE"
    exit 2
  fi

  # iterate paths file (ignore blanks and comments)
  while IFS= read -r raw || [ -n "$raw" ]; do
    path="$(echo "$raw" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')"
    [ -z "$path" ] && continue
    [[ "$path" =~ ^# ]] && continue

    # expand ~ and relative references
    # allow relative paths (relative to CWD) — expand_path attempts to make absolute
    if [[ "$path" = /* ]]; then
      abs="$path"
    else
      abs="$(pwd)/$path"
    fi

    # try to normalize
    if real_abs="$(cd "$abs" >/dev/null 2>&1 && pwd)"; then
      abs="$real_abs"
    else
      # try to expand ~ if present
      if [[ "$path" = ~* ]]; then
        expanded="${path/#\~/$HOME}"
        if real_abs="$(cd "$expanded" >/dev/null 2>&1 && pwd)"; then
          abs="$real_abs"
        else
          err "Skipping unreadable path: $path"
          continue
        fi
      else
        err "Skipping unreadable path: $path"
        continue
      fi
    fi

    if scan_one_project "$abs"; then
      ANY_FOUND=1
    fi
    echo
  done < "$PATHS_FILE"
else
  # single-directory mode: current directory
  if scan_one_project "$(pwd)"; then
    ANY_FOUND=1
  fi
fi

# final exit code
if [ "$ANY_FOUND" -ne 0 ]; then
  info "==> One or more compromised packages were found in scanned projects."
  exit 1
else
  info "==> No compromised packages found in scanned projects."
  exit 0
fi
